{"cells":[{"cell_type":"markdown","metadata":{"id":"h8NG0Jpo03qa"},"source":["# 3.2.3. T-distributed Stochastic Neighbor Embedding"]},{"cell_type":"markdown","metadata":{"id":"jvtkjFym03qb"},"source":["## Preparación del Entorno"]},{"cell_type":"markdown","metadata":{"id":"a1Es-xvb03qc"},"source":["### Carga de Módulos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpPZfwKr03qc"},"outputs":[],"source":["import math\n","import os\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib import offsetbox\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.io as pio\n","import plotly.figure_factory as ff\n","import session_info\n","from time import time\n","from plotly.subplots import make_subplots\n","from sklearn import set_config\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.decomposition import PCA\n","import sys\n","\n","sys.path.append('../scripts')\n","\n","# Tema Principal\n","from sklearn.manifold import TSNE\n","from funny_stuffs import generate_contrast_colors, plot_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuR3Dg6y03qi","outputId":"fe97e07c-6ee6-469d-99e7-f14ad3a4dd73"},"outputs":[],"source":["session_info.show()"]},{"cell_type":"markdown","metadata":{"id":"e2livaH903qi"},"source":["### Configuración Inicial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79eWXZk503qj"},"outputs":[],"source":["random_seed = 333  # Semilla para reproducibilidad de resultados\n","np.random.seed(random_seed)  # Para reproducibilidad\n","\n","# Configuración de opciones de visualización para pandas\n","pd.set_option('display.max_columns', None)  # Muestra todas las columnas\n","pd.set_option('display.max_rows', 15)  # Ajusta el número de filas a mostrar\n","\n","# Configuraciones extras\n","sns.set_style('dark')\n","dark_template = pio.templates['plotly_dark'].to_plotly_json()\n","dark_template['layout']['paper_bgcolor'] = 'rgba(30, 30, 30, 0.5)'\n","dark_template['layout']['plot_bgcolor'] = 'rgba(30, 30, 30, 0.5)'\n","pio.templates['plotly_dark_semi_transparent'] = go.layout.Template(dark_template)\n","pio.templates.default = 'plotly_dark_semi_transparent'\n","#set_config(transform_output=\"pandas\")\n","set_config(display='diagram')\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"RJ-6emQg03qj"},"source":["## T-distributed Stochastic Neighbor Embedding"]},{"cell_type":"markdown","metadata":{"id":"i7t16uPB03qj"},"source":["### Fundamento Teórico"]},{"cell_type":"markdown","metadata":{"id":"eemyKB8m03qj"},"source":["La Incrustación Estocástica de Vecinos T-Describuidos (*t-SNE T-distributed Stochastic Neighbor Embedding* en inglés) es una técnica de reducción de dimensionalidad enfocada en la visualización de datos complejos, transformando distancias entre puntos en probabilidades para preservar la estructura de los datos al reducirlos a dos o tres dimensiones. Optimiza la ubicación de los puntos en el espacio reducido para que su distribución de probabilidades se asemeje a la del espacio original.\n","\n","Para realizar el procedimiento, debemos de hacer lo siguiente:"]},{"cell_type":"markdown","metadata":{},"source":["#### 1. Obtener las Probabilidades Conjuntas en el Espacio de Alta Dimensión"]},{"cell_type":"markdown","metadata":{"id":"HDPTj6IO03qj"},"source":["Dado un conjunto de datos $\\{x_1, x_2, ..., x_n\\}$, t-SNE comienza calculando probabilidades conjuntas $p_{ij}$ que representan similitudes entre pares de puntos. La probabilidad conjunta $p_{ij}$ es simétrica y se define mediante la media de las probabilidades condicionales $p_{j|i}$ y $p_{i|j}$, donde $p_{j|i}$ se calcula como sigue:\n","\n","$$\n","p_{j|i} = \\frac{\\exp(-||x_i - x_j||^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i}\\exp(-||x_i - x_k||^2 / 2\\sigma_i^2)}\n","$$\n","\n","y la probabilidad conjunta $p_{ij}$ se define como:\n","\n","$$\n","p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2n}\n","$$\n","\n","La desviación estándar $\\sigma_i$ para cada punto $x_i$ no es constante para todos los puntos; en cambio, se ajusta individualmente para cada punto de manera que la distribución de las probabilidades condicionales $p_{j|i}$ cumpla con un valor de perplejidad predefinido: \n","\n","$$\n","\\text{Perplejidad} = 2^{H(P_i)}\n","$$\n","\n","donde $H(P_i)$ es la entropía de Shannon de la distribución de probabilidad condicional $P_i$ y se calcula como:\n","\n","$$\n","H(P_i) = -\\sum_j p_{j|i} \\log_2 p_{j|i}\n","$$"]},{"cell_type":"markdown","metadata":{},"source":["#### Proceso de Busqueda (Opcional)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ¿Cómo es el proceso de busqueda\n","\n","# Datos de ejemplo\n","x1 = np.array([0, 0])\n","x2 = np.array([1, 0])\n","x3 = np.array([0, 1])\n","\n","# Inicialización de sigma\n","sigma1 = 10\n","perplexity = 2.0\n","desired_entropy = np.log2(perplexity)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Función para calcular las probabilidades condicionales\n","def compute_probabilities(x_i, x_j, x_k, sigma_i):\n","    dist_ij = np.linalg.norm(x_i - x_j)\n","    dist_ik = np.linalg.norm(x_i - x_k)\n","    numerator = np.exp(-dist_ij**2 / (2 * sigma_i**2))\n","    denominator = np.exp(-dist_ij**2 / (2 * sigma_i**2)) + np.exp(-dist_ik**2 / (2 * sigma_i**2))\n","    p_ji = numerator / denominator\n","    return p_ji, 1 - p_ji\n","\n","# Función para calcular la entropía de Shannon\n","def compute_entropy(p_ji, p_ki):\n","    return -p_ji * np.log2(p_ji) - p_ki * np.log2(p_ki)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Búsqueda de sigma_i utilizando búsqueda binaria\n","max_iter = 100\n","tol = 1e-5\n","lower_bound = 1e-10\n","upper_bound = 50.0\n","\n","for _ in range(max_iter):\n","    p_2_1, p_3_1 = compute_probabilities(x1, x2, x3, sigma1)\n","    entropy = compute_entropy(p_2_1, p_3_1)\n","    if np.abs(entropy - desired_entropy) < tol:\n","        break\n","    if entropy < desired_entropy:\n","        lower_bound = sigma1\n","        sigma1 = (sigma1 + upper_bound) / 2\n","    else:\n","        upper_bound = sigma1\n","        sigma1 = (sigma1 + lower_bound) / 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sigma1, p_2_1, p_3_1, entropy"]},{"cell_type":"markdown","metadata":{},"source":["2.**Obtener las Probabilidades Conjuntas en el Espacio de Baja Dimensión**:\n","\n","En el espacio de baja dimensión, buscamos encontrar los puntos $\\{y_1, y_2, ..., y_n\\}$ tal que las similitudes entre los puntos $q_{ij}$ reflejen las similitudes $p_{ij}$ del espacio de alta dimensión. La probabilidad conjunta $q_{ij}$ en el espacio de baja dimensión se define utilizando una **distribución t-Student con un grado de libertad**  como:\n","\n","$$\n","q_{ij} = \\frac{(1 + ||y_i - y_j||^2)^{-1}}{\\sum_{k \\neq l}(1 + ||y_k - y_l||^2)^{-1}}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltt1hNT203qj","outputId":"bc48b1b3-7caf-403c-bef7-a9b2edc98592"},"outputs":[],"source":["# Efecto Crowding\n","normal_data = np.random.randn(1000)  # Distribución normal\n","student_data = np.random.standard_t(df=1, size=1000)  # Distribución t de Student con 1 grado de libertad\n","\n","# Filtrar los datos de valores atípicos extremos\n","normal_data = normal_data[np.abs(normal_data) < 10]\n","student_data = student_data[np.abs(student_data) < 10]\n","\n","fig = go.Figure()\n","fig.add_trace(go.Histogram(x=normal_data, nbinsx=50, name='Distribución Normal',\n","                           marker_color='skyblue', opacity=0.75))\n","fig.add_trace(go.Histogram(x=student_data, nbinsx=50, name='Distribución t-Student',\n","                           marker_color='orange', opacity=0.75))\n","\n","fig.update_layout(title_text='Distribución Normal vs t-Student',\n","                  xaxis_title_text='Value', yaxis_title_text='Count',\n","                  bargap=0.2,\n","                  barmode='overlay',\n","                  xaxis_range=[-10, 10])\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"HY79QO6q03qk"},"source":["3.**Minimización de la Divergencia de Kullback-Leibler**:\n","\n","El objetivo de t-SNE es minimizar la divergencia de Kullback-Leibler (KL) entre las distribuciones de probabilidad en los espacios de alta y baja dimensión, $P$ y $Q$ respectivamente. La divergencia KL se define como:\n","\n","$$\n","C = KL(P||Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\n","$$\n","\n","\n","4.**Optimización**:\n","\n","La minimización de la divergencia de KL se realiza a través de técnicas de optimización, típicamente utilizando el método de **descenso de gradiente**. El gradiente de $C$ (función de costo) con respecto a cada punto $y_i$ en el espacio de baja dimensión se calcula como:\n","\n","$$\n","\\frac{\\delta C}{\\delta y_i} = 4 \\sum_{j}(p_{ij} - q_{ij})(y_i - y_j)(1 + ||y_i - y_j||^2)^{-1}\n","$$\n","\n","El descenso de gradiente actualiza los puntos $Y$ para minimizar $C$. La actualización se realiza de la siguiente manera:\n","\n","$$\n","y_i^{(t+1)} = y_i^{(t)} - \\eta \\frac{\\delta C}{\\delta y_i}\n","$$\n","\n","donde:\n","\n","- $y_i^{(t)}$ es la posición del punto $y_i$ en la iteración $t$.\n","- $\\eta$ es la tasa de aprendizaje.\n","- $\\frac{\\delta C}{\\delta y_i}$ es el gradiente de la función de costo con respecto a $y_i$.\n","- \n","\n","El procedimiento de optimización ajusta iterativamente las posiciones $y_i$ en el espacio de baja dimensión para minimizar la divergencia KL, lo que resulta en una configuración de puntos que refleja fielmente las similitudes originales del espacio de alta dimensión."]},{"cell_type":"markdown","metadata":{"id":"ORpMvzcr03qk"},"source":["#### Aplicaciónes y Limitaciones"]},{"cell_type":"markdown","metadata":{"id":"aS2xeDNb03qk"},"source":["<p style=\"font-size:25px;\">Aplicaciones</p>\n","\n","1. Visualización de Datos Multidimensionales\n","2. Exploración de Datos\n","3. Agrupación\n","4. Detección de Anomalías\n","5. Validación de Modelos\n","\n","\n","<p style=\"font-size:25px;\">Limitaciones</p>\n","\n","1. Costo Computacional\n","2. Sensibilidad a Hiperparámetros\n","3. Falta de Consistencia\n","4. No Preserva la Densidad Global\n","5. Dificultad en la Interpretación de Distancias\n","6. Tendencia al Overfitting\n","7. No es Determinístico"]},{"cell_type":"markdown","metadata":{"id":"GRTxRIdo03qk"},"source":["### Ejemplo Práctico"]},{"cell_type":"markdown","metadata":{"id":"uy5Dxi7u03qk"},"source":["#### Preparación de los Datos"]},{"cell_type":"markdown","metadata":{"id":"XlIclyuq03qk"},"source":["**Descripción del conjunto de datos:**\n","\n","El conjunto de datos **Digits dataset**, es una colección de dígitos escritos a mano, contiene 1,797 imágenes en total.\n","\n","Cada imagen es de `8x8` píxeles, lo que significa que cada imagen se representa como una matriz 2D de 8x8 o como un vector unidimensional de 64 píxeles al aplanarse. Estas están en escala de grises, con valores de píxeles que varían de 0 a 16. Esto representa la intensidad del píxel, donde un valor más alto corresponde a un píxel más oscuro.\n","\n","Cada imagen viene con una etiqueta asociada que indica el dígito real que representa (entre 0 y 9)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"My6-b6FR03qk"},"outputs":[],"source":["X, y = pd.read_pickle('../data/digits.pkl')\n","n_samples, n_features = X.shape\n","n_neighbors = 30"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeAwP4Qx03qk","outputId":"d0afc89b-a959-4255-d92d-a89772c66998"},"outputs":[],"source":["#Muestra Dígitos\n","num_rows = 5\n","num_cols = 5\n","\n","fig = make_subplots(\n","    rows=num_rows,\n","    cols=num_cols,\n","    subplot_titles=[None]*num_rows*num_cols)\n","\n","for i in range(num_rows):\n","    for j in range(num_cols):\n","        index = i * num_cols + j\n","        image = X[index].reshape((8, 8))\n","\n","        fig.add_trace(\n","            go.Heatmap(\n","                z=image,\n","                colorscale='Greys',\n","                showscale=False,\n","                hoverinfo='skip'\n","            ),\n","            row=i+1, col=j+1\n","        )\n","\n","fig.update_layout(\n","    title_text='Conjunto de Dígitos',\n","    height=800,\n","    width=500,\n","    margin=dict(t=50, l=25, r=25, b=25),\n","    showlegend=False\n",")\n","\n","fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False)\n","fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"HjoG2xzM03ql"},"source":["#### Implementación del Método"]},{"cell_type":"markdown","metadata":{"id":"qHHb3Vic03ql"},"source":["Principales parámetros de t-SNE:\n","```python\n","TSNE(\n","    n_components=2,                # Parámetro Clave\n","    perplexity=30.0,               # Parámetro Clave\n","    early_exaggeration=12.0,       # Parámetro Clave\n","    learning_rate='auto',          # Parámetro Clave\n","    n_iter=1000,                   # Parámetro Clave\n","    n_iter_without_progress=300,\n","    min_grad_norm=1e-07,\n","    metric_params=None,\n","    init='pca',\n","    random_state=None,\n",")"]},{"cell_type":"markdown","metadata":{"id":"mDCXd3eQ03ql"},"source":["#### Visualización e Implementación de Resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6TNAAXKM03ql"},"outputs":[],"source":["reductor = {\n","    \"PCA\": PCA(n_components=2,\n","                        random_state=42),\n","\n","    \"t-SNE\": TSNE(\n","        n_components=2,\n","        n_iter=500,\n","        perplexity = 30,\n","        n_iter_without_progress=150,\n","        random_state=random_seed\n","    ),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Azk-qaiU03ql"},"outputs":[],"source":["projections, timing = {}, {}\n","for name, reducto in reductor.items():\n","    start_time = time()\n","    projections[name] = reducto.fit_transform(X, y)\n","    timing[name] = time() - start_time"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
